{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T18:35:11.632400Z",
     "iopub.status.busy": "2025-08-06T18:35:11.632139Z",
     "iopub.status.idle": "2025-08-06T18:35:17.894941Z",
     "shell.execute_reply": "2025-08-06T18:35:17.893864Z",
     "shell.execute_reply.started": "2025-08-06T18:35:11.632373Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip -q install -U iterative-stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T18:35:17.896678Z",
     "iopub.status.busy": "2025-08-06T18:35:17.896364Z",
     "iopub.status.idle": "2025-08-06T18:35:17.903262Z",
     "shell.execute_reply": "2025-08-06T18:35:17.902323Z",
     "shell.execute_reply.started": "2025-08-06T18:35:17.896645Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing convert_npy_to_png.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile convert_npy_to_png.py\n",
    "#src/features/convert_npy_to_png.py\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "def normalize_to_uint8(img):\n",
    "    img = np.clip(img, 0, 10000)\n",
    "    img = img / 10000.0\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "def convert_npy_to_png(npy_folder, output_folder, bands=[3,2,1]):\n",
    "    npy_folder = Path(npy_folder)\n",
    "    output_folder = Path(output_folder)\n",
    "    output_folder.mkdir(parents=True, exist_ok=True)\n",
    "    for filename in tqdm(os.listdir(npy_folder), desc=f\"Converting {npy_folder.name}\"):\n",
    "        if filename.endswith(\".npy\"):\n",
    "            path = npy_folder / filename\n",
    "            data = np.load(path)\n",
    "            rgb = data[:, :, bands]\n",
    "            rgb = normalize_to_uint8(rgb)\n",
    "            image_pil = Image.fromarray(rgb)\n",
    "            out_path = output_folder / filename.replace(\".npy\", \".png\")\n",
    "            image_pil.save(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T18:35:17.905425Z",
     "iopub.status.busy": "2025-08-06T18:35:17.905208Z",
     "iopub.status.idle": "2025-08-06T18:35:17.927362Z",
     "shell.execute_reply": "2025-08-06T18:35:17.926455Z",
     "shell.execute_reply.started": "2025-08-06T18:35:17.905407Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train_efficientnet.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train_efficientnet.py\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "import timm\n",
    "from torch.nn.functional import sigmoid\n",
    "from config_efficientnet import CFG, seed_everything\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "seed_everything(CFG.seed)\n",
    "\n",
    "# === Dataset ===\n",
    "class SentinelDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None, to_train=True):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "        self.to_train = to_train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        img_path = row['path']\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "        if image is None:\n",
    "            raise FileNotFoundError(f\"Could not read image at {img_path}\")\n",
    "        if image.ndim == 2:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "        elif image.shape[2] == 4:\n",
    "            image = image[:, :, :3]\n",
    "        if self.transform:\n",
    "            image = self.transform(image=image)[\"image\"]\n",
    "        if self.to_train:\n",
    "            target = torch.tensor(row[\"label\"], dtype=torch.float32)\n",
    "            return image, target\n",
    "        return image\n",
    "\n",
    "# === Model ===\n",
    "class EfficientNetV2Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(\"efficientnetv2_rw_m\", pretrained=True)\n",
    "        in_features = self.backbone.classifier.in_features\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "        self.classifier = nn.Linear(in_features, 1)\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        return self.classifier(features)\n",
    "\n",
    "# === Transforms ===\n",
    "train_transforms = A.Compose([\n",
    "    A.Resize(CFG.img_size, CFG.img_size),\n",
    "    A.Rotate(limit=30, p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=0, p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "    A.HueSaturationValue(hue_shift_limit=5, p=0.3),\n",
    "    A.CoarseDropout(max_holes=8, max_height=32, max_width=32, p=0.5),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "test_transforms = A.Compose([\n",
    "    A.Resize(CFG.img_size, CFG.img_size),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# === Training ===\n",
    "def train_one_fold(fold, train_loader, val_loader, model_dir):\n",
    "    seed_everything(42)\n",
    "    model = EfficientNetV2Classifier().cuda()\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=CFG.lr)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CFG.epochs)  # <-- FIX: match script\n",
    "    scaler = torch.amp.GradScaler('cuda')\n",
    "    best_loss = float(\"inf\")\n",
    "    fold_path = Path(model_dir) / f\"fold_{fold+1}\"\n",
    "    fold_path.mkdir(parents=True, exist_ok=True)\n",
    "    best_model_path = fold_path / \"best.pt\"\n",
    "\n",
    "    for epoch in range(CFG.epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        for images, targets in tqdm(train_loader, desc=f\"Fold {fold+1} Epoch {epoch+1}/{CFG.epochs} - Train\"):\n",
    "            images, targets = images.cuda(), targets.cuda().unsqueeze(1).float()\n",
    "            optimizer.zero_grad()\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, targets)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            epoch_loss += loss.item()\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.inference_mode():\n",
    "            for images, targets in val_loader:\n",
    "                images, targets = images.cuda(), targets.cuda().unsqueeze(1).float()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "        val_loss /= len(val_loader)\n",
    "        print(f\"Fold {fold+1} Epoch {epoch+1}: Train Loss {epoch_loss/len(train_loader):.4f}, Val Loss {val_loss:.4f}\")\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "        scheduler.step()\n",
    "    return best_model_path\n",
    "\n",
    "# === Main Training ===\n",
    "def train_efficientnet(train_csv, test_csv, train_imgs, test_imgs, model_dir):\n",
    "    train_df = pd.read_csv(train_csv)\n",
    "    test_df = pd.read_csv(test_csv)\n",
    "    train_df = train_df.groupby(\"ID\").sum().reset_index()[[\"ID\", \"label\"]]\n",
    "    train_df[\"path\"] = train_imgs + \"/\" + train_df[\"ID\"] + \".png\"\n",
    "    test_df[\"path\"] = test_imgs + \"/\" + test_df[\"ID\"] + \".png\"\n",
    "    skf = StratifiedKFold(n_splits=CFG.folds, shuffle=True, random_state=CFG.seed)\n",
    "    train_df[\"stratify_label\"] = train_df[[\"label\"]].sum(axis=1)\n",
    "    for fold, (_, valid_idx) in enumerate(skf.split(train_df, train_df[\"stratify_label\"])):\n",
    "        train_df.loc[valid_idx, \"fold\"] = fold\n",
    "    for fold in range(CFG.folds):\n",
    "        train_data = train_df[train_df[\"fold\"] != fold].reset_index(drop=True)\n",
    "        valid_data = train_df[train_df[\"fold\"] == fold].reset_index(drop=True)\n",
    "        train_loader = DataLoader(SentinelDataset(train_data, transform=train_transforms), batch_size=CFG.batch_size, shuffle=True, num_workers=os.cpu_count())\n",
    "        val_loader = DataLoader(SentinelDataset(valid_data, transform=test_transforms), batch_size=CFG.batch_size, shuffle=False)\n",
    "        train_one_fold(fold, train_loader, val_loader, model_dir)\n",
    "\n",
    "# === Inference (Ensemble of folds) ===\n",
    "def infer_efficientnet(test_csv, test_imgs, model_dir, out_csv):\n",
    "    test_df = pd.read_csv(test_csv)\n",
    "    test_df[\"path\"] = test_imgs + \"/\" + test_df[\"ID\"] + \".png\"\n",
    "    test_loader = DataLoader(SentinelDataset(test_df, transform=test_transforms, to_train=False), batch_size=CFG.batch_size, shuffle=False)\n",
    "    probs = np.zeros(len(test_df))\n",
    "    model = EfficientNetV2Classifier().cuda()\n",
    "    for fold in range(CFG.folds):\n",
    "        fold_model = Path(model_dir) / f\"fold_{fold+1}\" / \"best.pt\"\n",
    "        model.load_state_dict(torch.load(fold_model))\n",
    "        model.eval()\n",
    "        fold_preds = []\n",
    "        with torch.inference_mode():\n",
    "            for images in tqdm(test_loader, desc=f\"Inference Fold {fold+1}\"):\n",
    "                images = images.cuda()\n",
    "                logits = model(images)\n",
    "                preds = sigmoid(logits).squeeze(1).cpu().numpy()\n",
    "                fold_preds.append(preds)\n",
    "        probs += np.concatenate(fold_preds)\n",
    "    probs /= CFG.folds\n",
    "    pd.DataFrame({\"ID\": test_df[\"ID\"], \"probability\": probs}).to_csv(out_csv, index=False)\n",
    "    print(f\"✅ Predictions saved to {out_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T18:35:17.929113Z",
     "iopub.status.busy": "2025-08-06T18:35:17.928820Z",
     "iopub.status.idle": "2025-08-06T18:35:17.950914Z",
     "shell.execute_reply": "2025-08-06T18:35:17.950101Z",
     "shell.execute_reply.started": "2025-08-06T18:35:17.929085Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing config_efficientnet.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile config_efficientnet.py\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class CFG:\n",
    "    seed = 42\n",
    "    folds = 5\n",
    "    epochs = 20\n",
    "    img_size = 320\n",
    "    batch_size = 16\n",
    "    lr = 1e-4\n",
    "\n",
    "def seed_everything(seed=CFG.seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(True, warn_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T18:35:17.951845Z",
     "iopub.status.busy": "2025-08-06T18:35:17.951642Z",
     "iopub.status.idle": "2025-08-06T18:35:17.971610Z",
     "shell.execute_reply": "2025-08-06T18:35:17.970779Z",
     "shell.execute_reply.started": "2025-08-06T18:35:17.951826Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing main_efficientnet.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main_efficientnet.py\n",
    "\n",
    "import argparse\n",
    "from convert_npy_to_png import convert_npy_to_png\n",
    "from pathlib import Path\n",
    "from train_efficientnet import train_efficientnet, infer_efficientnet\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--mode\", choices=[\"train\", \"infer\"], required=True)\n",
    "    parser.add_argument(\"--train_csv\", type=str, default=\"/kaggle/input/slideandseekclasificationlandslidedetectiondataset/Train.csv\")\n",
    "    parser.add_argument(\"--test_csv\", type=str, default=\"/kaggle/input/slideandseekclasificationlandslidedetectiondataset/Test.csv\")\n",
    "    parser.add_argument(\"--train_npy_dir\", type=str, default=\"/kaggle/input/slideandseekclasificationlandslidedetectiondataset/train_data/train_data\")\n",
    "    parser.add_argument(\"--test_npy_dir\", type=str, default=\"/kaggle/input/slideandseekclasificationlandslidedetectiondataset/test_data/test_data\")\n",
    "    parser.add_argument(\"--image_dir\", type=str, default=\"train_data_sentinel_png\")\n",
    "    parser.add_argument(\"--test_dir\", type=str, default=\"test_data_sentinel_png\")\n",
    "    parser.add_argument(\"--model_dir\", type=str, default=\"models/efficientnet\")\n",
    "    parser.add_argument(\"--output_path\", type=str, default=\"efficientnet_submission_probs.csv\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.mode == \"train\":\n",
    "        # Step 1: Convert npy → png (if not already done)\n",
    "        if not Path(args.image_dir).exists() or len(list(Path(args.image_dir).glob(\"*.png\"))) == 0:\n",
    "            print(f\"⚙️ Converting training npy files from {args.train_npy_dir} to PNG at {args.image_dir}\")\n",
    "            convert_npy_to_png(args.train_npy_dir, args.image_dir)\n",
    "        if not Path(args.test_dir).exists() or len(list(Path(args.test_dir).glob(\"*.png\"))) == 0:\n",
    "            print(f\"⚙️ Converting test npy files from {args.test_npy_dir} to PNG at {args.test_dir}\")\n",
    "            convert_npy_to_png(args.test_npy_dir, args.test_dir)\n",
    "\n",
    "        # Step 2: Train YOLO models\n",
    "        train_efficientnet(args.train_csv, args.test_csv, args.image_dir, args.test_dir, args.model_dir)\n",
    "\n",
    "    elif args.mode == \"infer\":\n",
    "        infer_efficientnet(args.test_csv,args.test_dir, args.model_dir, args.output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-06T18:42:38.302Z",
     "iopub.execute_input": "2025-08-06T18:35:17.972484Z",
     "iopub.status.busy": "2025-08-06T18:35:17.972273Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "⚙️ Converting training npy files from /kaggle/input/slideandseekclasificationlandslidedetectiondataset/train_data/train_data to PNG at train_data_sentinel_png\n",
      "Converting train_data: 100%|████████████████| 7147/7147 [01:21<00:00, 87.65it/s]\n",
      "⚙️ Converting test npy files from /kaggle/input/slideandseekclasificationlandslidedetectiondataset/test_data/test_data to PNG at test_data_sentinel_png\n",
      "Converting test_data: 100%|█████████████████| 5397/5397 [01:00<00:00, 89.40it/s]\n",
      "model.safetensors: 100%|██████████████████████| 214M/214M [00:00<00:00, 232MB/s]\n",
      "Fold 1 Epoch 1/20 - Train: 100%|██████████████| 358/358 [02:05<00:00,  2.84it/s]\n",
      "Fold 1 Epoch 1: Train Loss 0.3099, Val Loss 0.1673\n",
      "Fold 1 Epoch 2/20 - Train: 100%|██████████████| 358/358 [02:05<00:00,  2.86it/s]\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "!python main_efficientnet.py --mode train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-06T18:42:38.303Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Infer\n",
    "!python main_efficientnet.py --mode infer"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7191644,
     "sourceId": 11474913,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
