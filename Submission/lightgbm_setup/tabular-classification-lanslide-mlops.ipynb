{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7686db98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T19:04:03.997810Z",
     "iopub.status.busy": "2025-08-06T19:04:03.997422Z",
     "iopub.status.idle": "2025-08-06T19:04:04.013085Z",
     "shell.execute_reply": "2025-08-06T19:04:04.012110Z"
    },
    "papermill": {
     "duration": 0.021819,
     "end_time": "2025-08-06T19:04:04.014933",
     "exception": false,
     "start_time": "2025-08-06T19:04:03.993114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing extract_band_stats.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile extract_band_stats.py\n",
    "# src/features/extract_band_stats.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.stats import kurtosis, skew\n",
    "\n",
    "# CONFIG\n",
    "BANDS = [f\"B{i}\" for i in range(1, 13)]\n",
    "N_JOBS = 4\n",
    "\n",
    "def process_npy_file(row):\n",
    "    try:\n",
    "        file_path = Path(row[\"sentinel_path\"])\n",
    "        ID = row[\"ID\"]\n",
    "\n",
    "        if not file_path.exists():\n",
    "            logging.warning(f\"[MISSING] {file_path}\")\n",
    "            return None\n",
    "\n",
    "        arr = np.load(file_path)  # (H, W, 12)\n",
    "        if arr.shape[-1] != 12:\n",
    "            logging.warning(f\"[SKIPPED] {ID}: got {arr.shape}\")\n",
    "            return None\n",
    "\n",
    "        H, W = arr.shape[:2]\n",
    "        flat_pixels = arr.reshape(-1, 12)\n",
    "        valid = ~np.all(flat_pixels == 0, axis=1)\n",
    "        flat_pixels = flat_pixels[valid]\n",
    "\n",
    "        if flat_pixels.shape[0] == 0:\n",
    "            logging.warning(f\"[EMPTY] {ID}\")\n",
    "            return None\n",
    "\n",
    "        df = pd.DataFrame(flat_pixels, columns=BANDS)\n",
    "        df[\"ID\"] = ID\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.error(f\"[ERROR] {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def summarize_id_stats(group_tuple):\n",
    "    ID, df = group_tuple\n",
    "    stats = {\"ID\": ID}\n",
    "    for band in BANDS:\n",
    "        vals = df[band].values\n",
    "        finite = vals[np.isfinite(vals)]\n",
    "        if finite.size == 0: continue\n",
    "        stats.update({\n",
    "            f\"{band}_mean\": np.mean(finite),\n",
    "            f\"{band}_median\": np.median(finite),\n",
    "            f\"{band}_min\": np.min(finite),\n",
    "            f\"{band}_max\": np.max(finite),\n",
    "            f\"{band}_std\": np.std(finite),\n",
    "            f\"{band}_kurtosis\": kurtosis(finite),\n",
    "            f\"{band}_skew\": skew(finite),\n",
    "            f\"{band}_q25\": np.percentile(finite, 25),\n",
    "            f\"{band}_q75\": np.percentile(finite, 75),\n",
    "        })\n",
    "    return stats\n",
    "\n",
    "def extract_features(train_df, test_df, output_dir=\"output\"):\n",
    "    Path(output_dir).mkdir(exist_ok=True, parents=True)\n",
    "    logging.info(\"=== Extracting Sentinel-2 features ===\")\n",
    "\n",
    "    df_all = pd.concat([train_df.assign(split='train'), test_df.assign(split='test')])\n",
    "\n",
    "    with Parallel(n_jobs=N_JOBS) as parallel:\n",
    "        results = parallel(delayed(process_npy_file)(row) for _, row in tqdm(df_all.iterrows(), total=len(df_all)))\n",
    "\n",
    "    valid_results = [r for r in results if r is not None]\n",
    "    if not valid_results:\n",
    "        raise RuntimeError(\"No valid .npy files processed.\")\n",
    "\n",
    "    pxdf = pd.concat(valid_results, ignore_index=True)\n",
    "    logging.info(f\"Pixel data shape: {pxdf.shape}\")\n",
    "\n",
    "    id_groups = pxdf.groupby(\"ID\")\n",
    "    with Parallel(n_jobs=N_JOBS) as parallel:\n",
    "        stats_list = parallel(delayed(summarize_id_stats)(group) for group in tqdm(id_groups, total=len(id_groups)))\n",
    "\n",
    "    agg_df = pd.DataFrame(stats_list)\n",
    "    agg_df.to_csv(Path(output_dir) / \"agg_df.csv\", index=False)\n",
    "\n",
    "    train_features = train_df.merge(agg_df, on=\"ID\", how=\"left\")\n",
    "    test_features = test_df.merge(agg_df, on=\"ID\", how=\"left\")\n",
    "    train_features.to_csv(Path(output_dir) / \"train_features.csv\", index=False)\n",
    "    test_features.to_csv(Path(output_dir) / \"test_features.csv\", index=False)\n",
    "\n",
    "    return train_features, test_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42bef095",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T19:04:04.021257Z",
     "iopub.status.busy": "2025-08-06T19:04:04.020972Z",
     "iopub.status.idle": "2025-08-06T19:04:04.027020Z",
     "shell.execute_reply": "2025-08-06T19:04:04.025849Z"
    },
    "papermill": {
     "duration": 0.010659,
     "end_time": "2025-08-06T19:04:04.028459",
     "exception": false,
     "start_time": "2025-08-06T19:04:04.017800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing feature_engineering_lightgbm.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile feature_engineering_lightgbm.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# === Feature Engineering ===\n",
    "def add_band_indices(df):\n",
    "    df['B4_B3_ratio'] = df['B4_mean'] / (df['B3_mean'] + 1e-6)\n",
    "    df['B3_B2_ratio'] = df['B3_mean'] / (df['B2_mean'] + 1e-6)\n",
    "    df['B2_B1_ratio'] = df['B2_mean'] / (df['B1_mean'] + 1e-6)\n",
    "    df['B4_B2_ratio'] = df['B4_mean'] / (df['B2_mean'] + 1e-6)\n",
    "    df['NDI_B4_B3'] = (df['B4_mean'] - df['B3_mean']) / (df['B4_mean'] + df['B3_mean'] + 1e-6)\n",
    "    df['NDI_B3_B2'] = (df['B3_mean'] - df['B2_mean']) / (df['B3_mean'] + df['B2_mean'] + 1e-6)\n",
    "    df['NDI_B2_B1'] = (df['B2_mean'] - df['B1_mean']) / (df['B2_mean'] + df['B1_mean'] + 1e-6)\n",
    "    df['SAR_diff'] = df['B8_mean'] - df['B5_mean']\n",
    "    return df\n",
    "\n",
    "def add_stat_features(df):\n",
    "    for b in range(1, 13):\n",
    "        df[f'B{b}_range'] = df[f'B{b}_max'] - df[f'B{b}_min']\n",
    "        df[f'B{b}_iqr'] = df[f'B{b}_q75'] - df[f'B{b}_q25']\n",
    "        df[f'B{b}_cv'] = df[f'B{b}_std'] / (df[f'B{b}_mean'] + 1e-6)\n",
    "    return df\n",
    "\n",
    "def add_texture_features(df):\n",
    "    for b in range(1, 13):\n",
    "        df[f'B{b}_texture'] = np.abs(df[f'B{b}_skew']) + np.abs(df[f'B{b}_kurtosis'])\n",
    "    return df\n",
    "\n",
    "def add_aggregations(df):\n",
    "    band_means = [f'B{i}_mean' for i in range(1,13)]\n",
    "    band_stds = [f'B{i}_std' for i in range(1,13)]\n",
    "    band_ranges = [f'B{i}_max' for i in range(1,13)]\n",
    "    df['mean_of_means'] = df[band_means].mean(axis=1)\n",
    "    df['std_of_means'] = df[band_means].std(axis=1)\n",
    "    df['sum_of_ranges'] = df[band_ranges].sum(axis=1)\n",
    "    df['std_of_stds'] = df[band_stds].std(axis=1)\n",
    "    return df\n",
    "\n",
    "def engineer_features(df):\n",
    "    df = add_band_indices(df)\n",
    "    df = add_stat_features(df)\n",
    "    df = add_texture_features(df)\n",
    "    df = add_aggregations(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "858007c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T19:04:04.034924Z",
     "iopub.status.busy": "2025-08-06T19:04:04.034547Z",
     "iopub.status.idle": "2025-08-06T19:04:04.043202Z",
     "shell.execute_reply": "2025-08-06T19:04:04.042200Z"
    },
    "papermill": {
     "duration": 0.013981,
     "end_time": "2025-08-06T19:04:04.045035",
     "exception": false,
     "start_time": "2025-08-06T19:04:04.031054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train_lightgbm.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train_lightgbm.py\n",
    "# src/models/train_lightgbm.py\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import joblib\n",
    "from feature_engineering_lightgbm import *\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import class_weight\n",
    "from pathlib import Path\n",
    "\n",
    "# === LightGBM Training ===\n",
    "def train_lgb(train_path, model_dir, n_splits=10):\n",
    "    df = pd.read_csv(train_path)\n",
    "    df = engineer_features(df)\n",
    "    X = df.drop(columns=['ID', 'sentinel_path','label'])\n",
    "    y = df['label']\n",
    "\n",
    "    classes = np.unique(y)\n",
    "    class_weights = class_weight.compute_class_weight('balanced', classes=classes, y=y)\n",
    "    sample_weights = class_weights[y]\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    models, f1_scores = [], []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        sw_train = sample_weights[train_idx]\n",
    "\n",
    "        train_data = lgb.Dataset(X_train, label=y_train, weight=sw_train)\n",
    "        val_data = lgb.Dataset(X_val, label=y_val)\n",
    "\n",
    "        params = {\n",
    "            'objective': 'binary',\n",
    "            'metric': 'binary_logloss',\n",
    "            'verbosity': -1,\n",
    "            'random_state': 42,\n",
    "            'early_stopping_rounds':100,\n",
    "        }\n",
    "\n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_data,\n",
    "            num_boost_round=1000,\n",
    "            valid_sets=[val_data],\n",
    "        )\n",
    "\n",
    "        y_proba = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "        y_pred = (y_proba > 0.5).astype(int)\n",
    "        fold_f1 = f1_score(y_val, y_pred)\n",
    "        f1_scores.append(fold_f1)\n",
    "        print(f\"Fold {fold+1} F1: {fold_f1:.4f}\")\n",
    "\n",
    "        Path(model_dir).mkdir(parents=True, exist_ok=True)\n",
    "        joblib.dump(model, f\"{model_dir}/lgb_fold{fold}.pkl\")\n",
    "        models.append(model)\n",
    "\n",
    "    print(f\"Mean F1: {np.mean(f1_scores):.4f}\")\n",
    "    return models\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--train_path\", type=str, default=\"output/train_features.csv\")\n",
    "    parser.add_argument(\"--model_dir\", type=str, default=\"models/lightgbm\")\n",
    "    args = parser.parse_args()\n",
    "    train_lgb(args.train_path, args.model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69a6aec6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T19:04:04.052337Z",
     "iopub.status.busy": "2025-08-06T19:04:04.051948Z",
     "iopub.status.idle": "2025-08-06T19:04:04.060083Z",
     "shell.execute_reply": "2025-08-06T19:04:04.058690Z"
    },
    "papermill": {
     "duration": 0.014618,
     "end_time": "2025-08-06T19:04:04.062497",
     "exception": false,
     "start_time": "2025-08-06T19:04:04.047879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing infer_lightgbm.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile infer_lightgbm.py\n",
    "# src/models/infer_lightgbm.py\n",
    "from feature_engineering_lightgbm import *\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "def predict_lgb(test_path, model_dir, output_path, threshold=0.55):\n",
    "    df = pd.read_csv(test_path)\n",
    "    df = engineer_features(df)\n",
    "    X = df.drop(columns=['ID', 'sentinel_path'])\n",
    "    ids = df['ID']\n",
    "    \n",
    "    models = [joblib.load(f\"{model_dir}/lgb_fold{i}.pkl\") for i in range(10)]\n",
    "    \n",
    "    probs = np.zeros(X.shape[0])\n",
    "    for model in models:\n",
    "        probs += model.predict(X, num_iteration=model.best_iteration)\n",
    "    probs /= len(models)\n",
    "    preds = (probs > threshold).astype(int)\n",
    "    \n",
    "    pd.DataFrame({\"ID\": ids, \"Probs\": probs}).to_csv(output_path.replace(\".csv\", \"_probs.csv\"), index=False)\n",
    "    pd.DataFrame({\"ID\": ids, \"Target\": preds}).to_csv(output_path, index=False)\n",
    "    print(f\"Saved predictions to {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--test_path\", type=str, required=True)\n",
    "    parser.add_argument(\"--model_dir\", type=str, required=True)\n",
    "    parser.add_argument(\"--output_path\", type=str, required=True)\n",
    "    args = parser.parse_args()\n",
    "    predict_lgb(args.test_path, args.model_dir, args.output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69cbaaa9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T19:04:04.073057Z",
     "iopub.status.busy": "2025-08-06T19:04:04.072449Z",
     "iopub.status.idle": "2025-08-06T19:04:04.079705Z",
     "shell.execute_reply": "2025-08-06T19:04:04.078749Z"
    },
    "papermill": {
     "duration": 0.014715,
     "end_time": "2025-08-06T19:04:04.081644",
     "exception": false,
     "start_time": "2025-08-06T19:04:04.066929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main.py\n",
    "# main.py\n",
    "import argparse\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Import the pipeline functions\n",
    "from extract_band_stats import extract_features\n",
    "from train_lightgbm import train_lgb\n",
    "from infer_lightgbm import predict_lgb\n",
    "import pandas as pd\n",
    "\n",
    "def main(mode, train_csv, test_csv, train_sentinel_dir, test_sentinel_dir, output_dir, model_dir, submission_path):\n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    Path(model_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if mode in [\"preprocess\", \"all\"]:\n",
    "        print(\"=== STEP 1: Feature Extraction ===\")\n",
    "        train_df = pd.read_csv(train_csv)\n",
    "        test_df = pd.read_csv(test_csv)\n",
    "        train_df['sentinel_path'] = train_df['ID'].apply(lambda id: os.path.join(train_sentinel_dir, f\"{id}.npy\"))\n",
    "        test_df['sentinel_path'] = test_df['ID'].apply(lambda id: os.path.join(test_sentinel_dir, f\"{id}.npy\"))\n",
    "        extract_features(train_df, test_df, output_dir=output_dir)\n",
    "\n",
    "    if mode in [\"train\", \"all\"]:\n",
    "        print(\"=== STEP 2: Training LightGBM ===\")\n",
    "        train_lgb(os.path.join(output_dir, \"train_features.csv\"), model_dir=model_dir)\n",
    "\n",
    "    if mode in [\"inference\", \"all\"]:\n",
    "        print(\"=== STEP 3: Inference ===\")\n",
    "        predict_lgb(\n",
    "            test_path=os.path.join(output_dir, \"test_features.csv\"),\n",
    "            model_dir=model_dir,\n",
    "            output_path=submission_path\n",
    "        )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--mode\", type=str, choices=[\"preprocess\", \"train\", \"inference\", \"all\"], required=True,\n",
    "                        help=\"Which step to run: preprocess | train | inference | all\")\n",
    "    parser.add_argument(\"--train_csv\", type=str, default=\"/kaggle/input/slideandseekclasificationlandslidedetectiondataset/Train.csv\")\n",
    "    parser.add_argument(\"--test_csv\", type=str, default=\"/kaggle/input/slideandseekclasificationlandslidedetectiondataset/Test.csv\")\n",
    "    parser.add_argument(\"--train_sentinel_dir\", type=str, default=\"/kaggle/input/slideandseekclasificationlandslidedetectiondataset/train_data/train_data/\")\n",
    "    parser.add_argument(\"--test_sentinel_dir\", type=str, default=\"/kaggle/input/slideandseekclasificationlandslidedetectiondataset/test_data/test_data/\")\n",
    "    parser.add_argument(\"--output_dir\", type=str, default=\"output\")\n",
    "    parser.add_argument(\"--model_dir\", type=str, default=\"models/lightgbm\")\n",
    "    parser.add_argument(\"--submission_path\", type=str, default=\"lgbm_submission.csv\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    main(\n",
    "        mode=args.mode,\n",
    "        train_csv=args.train_csv,\n",
    "        test_csv=args.test_csv,\n",
    "        train_sentinel_dir=args.train_sentinel_dir,\n",
    "        test_sentinel_dir=args.test_sentinel_dir,\n",
    "        output_dir=args.output_dir,\n",
    "        model_dir=args.model_dir,\n",
    "        submission_path=args.submission_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1ade346",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T19:04:04.092423Z",
     "iopub.status.busy": "2025-08-06T19:04:04.091471Z",
     "iopub.status.idle": "2025-08-06T19:08:51.934824Z",
     "shell.execute_reply": "2025-08-06T19:08:51.933395Z"
    },
    "papermill": {
     "duration": 287.851352,
     "end_time": "2025-08-06T19:08:51.937345",
     "exception": false,
     "start_time": "2025-08-06T19:04:04.085993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STEP 1: Feature Extraction ===\r\n",
      "100%|████████████████████████████████████| 12545/12545 [00:58<00:00, 216.05it/s]\r\n",
      "100%|█████████████████████████████████████| 12544/12544 [02:45<00:00, 75.58it/s]\r\n",
      "=== STEP 2: Training LightGBM ===\r\n",
      "Fold 1 F1: 0.8359\r\n",
      "Fold 2 F1: 0.8915\r\n",
      "Fold 3 F1: 0.8471\r\n",
      "Fold 4 F1: 0.8175\r\n",
      "Fold 5 F1: 0.8852\r\n",
      "Fold 6 F1: 0.8775\r\n",
      "Fold 7 F1: 0.8539\r\n",
      "Fold 8 F1: 0.8968\r\n",
      "Fold 9 F1: 0.8400\r\n",
      "Fold 10 F1: 0.8492\r\n",
      "Mean F1: 0.8595\r\n",
      "=== STEP 3: Inference ===\r\n",
      "Saved predictions to lgbm_submission.csv\r\n"
     ]
    }
   ],
   "source": [
    "!python main.py --mode all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165090e1",
   "metadata": {
    "papermill": {
     "duration": 0.056378,
     "end_time": "2025-08-06T19:08:52.051087",
     "exception": false,
     "start_time": "2025-08-06T19:08:51.994709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13018373,
     "datasetId": 7851548,
     "sourceId": 12446937,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 11919215,
     "datasetId": 7191644,
     "sourceId": 11474913,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 294.287694,
   "end_time": "2025-08-06T19:08:52.649655",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-06T19:03:58.361961",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
