{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T14:36:41.000668Z",
     "iopub.status.busy": "2025-08-06T14:36:41.000441Z",
     "iopub.status.idle": "2025-08-06T14:38:09.240083Z",
     "shell.execute_reply": "2025-08-06T14:38:09.239145Z",
     "shell.execute_reply.started": "2025-08-06T14:36:41.000643Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip -q install -U ultralytics iterative-stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T14:38:09.241980Z",
     "iopub.status.busy": "2025-08-06T14:38:09.241725Z",
     "iopub.status.idle": "2025-08-06T14:38:09.247731Z",
     "shell.execute_reply": "2025-08-06T14:38:09.247055Z",
     "shell.execute_reply.started": "2025-08-06T14:38:09.241958Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing convert_npy_to_png.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile convert_npy_to_png.py\n",
    "#src/features/convert_npy_to_png.py\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "def normalize_to_uint8(img):\n",
    "    img = np.clip(img, 0, 10000)\n",
    "    img = img / 10000.0\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "def convert_npy_to_png(npy_folder, output_folder, bands=[3,2,1]):\n",
    "    npy_folder = Path(npy_folder)\n",
    "    output_folder = Path(output_folder)\n",
    "    output_folder.mkdir(parents=True, exist_ok=True)\n",
    "    for filename in tqdm(os.listdir(npy_folder), desc=f\"Converting {npy_folder.name}\"):\n",
    "        if filename.endswith(\".npy\"):\n",
    "            path = npy_folder / filename\n",
    "            data = np.load(path)\n",
    "            rgb = data[:, :, bands]\n",
    "            rgb = normalize_to_uint8(rgb)\n",
    "            image_pil = Image.fromarray(rgb)\n",
    "            out_path = output_folder / filename.replace(\".npy\", \".png\")\n",
    "            image_pil.save(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T14:38:09.248540Z",
     "iopub.status.busy": "2025-08-06T14:38:09.248373Z",
     "iopub.status.idle": "2025-08-06T14:38:09.271138Z",
     "shell.execute_reply": "2025-08-06T14:38:09.270471Z",
     "shell.execute_reply.started": "2025-08-06T14:38:09.248526Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing config_yolo.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile config_yolo.py\n",
    "#src/utils/config_yolo.py\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class CFG:\n",
    "    seed = 42\n",
    "    batch=20\n",
    "    random_state = 42\n",
    "    folds = 10\n",
    "    epochs= 100\n",
    "    imgsz=320\n",
    "    device=0\n",
    "    optimizer='AdamW'\n",
    "    lr0=3e-4\n",
    "    momentum=0.9\n",
    "    weight_decay=1e-2\n",
    "    close_mosaic=30\n",
    "    seed=42\n",
    "    patience=10\n",
    "    threshold=0.5\n",
    "\n",
    "def seed_everything(seed=CFG.seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(True, warn_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T14:38:09.272255Z",
     "iopub.status.busy": "2025-08-06T14:38:09.272009Z",
     "iopub.status.idle": "2025-08-06T14:38:09.288493Z",
     "shell.execute_reply": "2025-08-06T14:38:09.287702Z",
     "shell.execute_reply.started": "2025-08-06T14:38:09.272229Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train_yolo.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train_yolo.py\n",
    "# src/models/train_yolo.py\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from config_yolo import CFG, seed_everything\n",
    "\n",
    "seed_everything(CFG.seed)\n",
    "\n",
    "# === Helper functions ===\n",
    "def prepare_classification_dir(df, base_dir):\n",
    "    \"\"\"Copy images into YOLO classification folder structure.\"\"\"\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=f'Preparing {base_dir.name}'):\n",
    "        img_path = Path(row['image_path'])\n",
    "        class_name = str(row['new_class'])\n",
    "        class_dir = base_dir / class_name\n",
    "        class_dir.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.copy2(img_path, class_dir / img_path.name)\n",
    "\n",
    "def prepare_test_dir(df, base_dir):\n",
    "    \"\"\"Copy test images into a flat directory.\"\"\"\n",
    "    for img_path in tqdm(df['image_path'].unique(), desc=f'Preparing test'):\n",
    "        shutil.copy2(img_path, base_dir / Path(img_path).name)\n",
    "\n",
    "# === Main training function ===\n",
    "def train_yolo(\n",
    "    train_csv,\n",
    "    test_csv,\n",
    "    images_dir,\n",
    "    model_dir,\n",
    "    folds=CFG.folds,\n",
    "    epochs=CFG.epochs,\n",
    "    imgsz=CFG.imgsz,\n",
    "    device=CFG.device,\n",
    "    batch=CFG.batch,\n",
    "    optimizer=CFG.optimizer,\n",
    "    lr0=CFG.lr0,\n",
    "    momentum=CFG.momentum,\n",
    "    weight_decay=CFG.weight_decay,\n",
    "    close_mosaic=CFG.close_mosaic,\n",
    "    seed=CFG.seed,\n",
    "    patience=CFG.patience\n",
    "):\n",
    "    # Load train/test\n",
    "    train = pd.read_csv(train_csv)\n",
    "    test = pd.read_csv(test_csv)\n",
    "\n",
    "    # Map class labels to indices\n",
    "    unique_classes = sorted(train['label'].unique())\n",
    "    full_label_dict = {cls: idx for idx, cls in enumerate(unique_classes)}\n",
    "    train['new_class'] = train['label'].map(full_label_dict)\n",
    "\n",
    "    # Group multilabels\n",
    "    grouped = train.groupby('ID')['new_class'].apply(list).reset_index()\n",
    "    for cls in unique_classes:\n",
    "        grouped[cls] = -1\n",
    "    reverse_mapping = {v: k for k, v in full_label_dict.items()}\n",
    "    for idx, labels in enumerate(grouped['new_class']):\n",
    "        for lbl in set(labels):\n",
    "            grouped.loc[idx, reverse_mapping[lbl]] = 1\n",
    "\n",
    "    # Multilabel stratified folds\n",
    "    grouped['fold'] = -1\n",
    "    mskf = MultilabelStratifiedKFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "    for i, (_, val_idx) in enumerate(mskf.split(grouped[['ID']], grouped[unique_classes])):\n",
    "        grouped.loc[val_idx, 'fold'] = i\n",
    "\n",
    "    # Add image paths\n",
    "    grouped['image_path'] = grouped['ID'].apply(lambda x: Path(images_dir) / f\"{x}.png\")\n",
    "    test['image_path'] = test['ID'].apply(lambda x: Path(images_dir.replace('train', 'test')) / f\"{x}.png\")\n",
    "\n",
    "    # Loop over folds\n",
    "    for fold in range(folds):\n",
    "        print(f\"\\n🚀 Training Fold {fold + 1}/{folds}\")\n",
    "\n",
    "        # Define directories\n",
    "        fold_root = Path(model_dir) / f'fold_{fold + 1}'\n",
    "        train_dir = fold_root / 'train'\n",
    "        val_dir = fold_root / 'val'\n",
    "        test_dir = Path(model_dir) / 'test/images'\n",
    "\n",
    "        # Clean dirs\n",
    "        for d in [train_dir, val_dir, test_dir]:\n",
    "            if d.exists():\n",
    "                shutil.rmtree(d)\n",
    "            d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Prepare data for YOLO classification\n",
    "        prepare_classification_dir(grouped[grouped['fold'] != fold], train_dir)\n",
    "        prepare_classification_dir(grouped[grouped['fold'] == fold], val_dir)\n",
    "        prepare_test_dir(test, test_dir)\n",
    "\n",
    "        # Train YOLO\n",
    "        model = YOLO(\"yolo11l-cls.pt\")\n",
    "        model.train(\n",
    "            data=str(fold_root),\n",
    "            epochs=epochs,\n",
    "            imgsz=imgsz,\n",
    "            device=device,\n",
    "            batch=batch,\n",
    "            optimizer=optimizer,\n",
    "            lr0=lr0,\n",
    "            momentum=momentum,\n",
    "            weight_decay=weight_decay,\n",
    "            close_mosaic=close_mosaic,\n",
    "            seed=seed,\n",
    "            patience=patience,\n",
    "            project=str(model_dir),\n",
    "            name=f\"fold_{fold + 1}\",\n",
    "            exist_ok=True\n",
    "        )\n",
    "\n",
    "        # Save best weights to fold-specific directory\n",
    "        src = Path(model_dir) / f\"fold_{fold + 1}/weights/best.pt\"\n",
    "        dst = fold_root / \"best.pt\"\n",
    "        shutil.copy(src, dst)\n",
    "        print(f\"✅ Fold {fold + 1} model saved at {dst}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T14:43:59.536633Z",
     "iopub.status.busy": "2025-08-06T14:43:59.536055Z",
     "iopub.status.idle": "2025-08-06T14:43:59.542460Z",
     "shell.execute_reply": "2025-08-06T14:43:59.541810Z",
     "shell.execute_reply.started": "2025-08-06T14:43:59.536602Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting infer_yolo.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile infer_yolo.py\n",
    "#src/models/infer_yolo.py\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "from config_yolo import seed_everything, CFG\n",
    "from tqdm import tqdm\n",
    "\n",
    "def infer_yolo(test_csv,test_dir, model_dir, output_path, folds=CFG.folds, threshold=0.5):\n",
    "    test = pd.read_csv(test_csv)\n",
    "    test_images_dir = Path(test_dir)\n",
    "    image_files = sorted(os.listdir(test_images_dir))\n",
    "    \n",
    "    all_probs = []\n",
    "    for fold in range(1, folds+1):\n",
    "        model = YOLO(str(Path(model_dir) / f'fold_{fold}/best.pt'))\n",
    "        fold_probs = []\n",
    "        for img in tqdm(image_files, desc=f\"Fold {fold} inference\"):\n",
    "            results = model(test_images_dir / img, verbose=False, imgsz=CFG.imgsz)\n",
    "            probs = results[0].probs.data.cpu().numpy()\n",
    "            fold_probs.append(float(probs[1]))  # Probability of class 1\n",
    "        all_probs.append(fold_probs)\n",
    "\n",
    "    # Average probabilities\n",
    "    probs_matrix = np.array(all_probs).T\n",
    "    avg_probs = probs_matrix.mean(axis=1)\n",
    "    preds = (avg_probs > threshold).astype(int)\n",
    "    \n",
    "    # Save\n",
    "    df = pd.DataFrame({\n",
    "        'ID': [f.replace('.png', '') for f in image_files],\n",
    "        'Probs': avg_probs,\n",
    "        'Predicted': preds\n",
    "    })\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"✅ Saved predictions to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T14:38:09.314726Z",
     "iopub.status.busy": "2025-08-06T14:38:09.314476Z",
     "iopub.status.idle": "2025-08-06T14:38:09.330307Z",
     "shell.execute_reply": "2025-08-06T14:38:09.329645Z",
     "shell.execute_reply.started": "2025-08-06T14:38:09.314698Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing main_yolo.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main_yolo.py\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from convert_npy_to_png import convert_npy_to_png\n",
    "from train_yolo import train_yolo\n",
    "from infer_yolo import infer_yolo\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--mode\", choices=[\"train\", \"infer\"], required=True)\n",
    "    parser.add_argument(\"--train_csv\", type=str, default=\"/kaggle/input/slideandseekclasificationlandslidedetectiondataset/Train.csv\")\n",
    "    parser.add_argument(\"--test_csv\", type=str, default=\"/kaggle/input/slideandseekclasificationlandslidedetectiondataset/Test.csv\")\n",
    "    parser.add_argument(\"--train_npy_dir\", type=str, default=\"/kaggle/input/slideandseekclasificationlandslidedetectiondataset/train_data/train_data\")\n",
    "    parser.add_argument(\"--test_npy_dir\", type=str, default=\"/kaggle/input/slideandseekclasificationlandslidedetectiondataset/test_data/test_data\")\n",
    "    parser.add_argument(\"--image_dir\", type=str, default=\"train_data_sentinel_png\")\n",
    "    parser.add_argument(\"--test_dir\", type=str, default=\"test_data_sentinel_png\")\n",
    "    parser.add_argument(\"--model_dir\", type=str, default=\"models/yolo\")\n",
    "    parser.add_argument(\"--output_path\", type=str, default=\"yolo_submission_probs_labels.csv\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.mode == \"train\":\n",
    "        # Step 1: Convert npy → png (if not already done)\n",
    "        if not Path(args.image_dir).exists() or len(list(Path(args.image_dir).glob(\"*.png\"))) == 0:\n",
    "            print(f\"⚙️ Converting training npy files from {args.train_npy_dir} to PNG at {args.image_dir}\")\n",
    "            convert_npy_to_png(args.train_npy_dir, args.image_dir)\n",
    "        if not Path(args.test_dir).exists() or len(list(Path(args.test_dir).glob(\"*.png\"))) == 0:\n",
    "            print(f\"⚙️ Converting test npy files from {args.test_npy_dir} to PNG at {args.test_dir}\")\n",
    "            convert_npy_to_png(args.test_npy_dir, args.test_dir)\n",
    "\n",
    "        # Step 2: Train YOLO models\n",
    "        train_yolo(args.train_csv, args.test_csv, args.image_dir, args.model_dir)\n",
    "\n",
    "    elif args.mode == \"infer\":\n",
    "        infer_yolo(args.test_csv,args.test_dir, args.model_dir, args.output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T14:38:09.331113Z",
     "iopub.status.busy": "2025-08-06T14:38:09.330944Z",
     "iopub.status.idle": "2025-08-06T14:43:00.587792Z",
     "shell.execute_reply": "2025-08-06T14:43:00.586890Z",
     "shell.execute_reply.started": "2025-08-06T14:38:09.331099Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "⚙️ Converting training npy files from /kaggle/input/slideandseekclasificationlandslidedetectiondataset/train_data/train_data to PNG at train_data_sentinel_png\n",
      "Converting train_data: 100%|████████████████| 7147/7147 [01:33<00:00, 76.04it/s]\n",
      "⚙️ Converting test npy files from /kaggle/input/slideandseekclasificationlandslidedetectiondataset/test_data/test_data to PNG at test_data_sentinel_png\n",
      "Converting test_data: 100%|█████████████████| 5397/5397 [01:05<00:00, 82.66it/s]\n",
      "\n",
      "🚀 Training Fold 1/2\n",
      "Preparing train: 100%|████████████████████| 3574/3574 [00:00<00:00, 4155.13it/s]\n",
      "Preparing val: 100%|██████████████████████| 3573/3573 [00:00<00:00, 4246.50it/s]\n",
      "Preparing test: 100%|█████████████████████| 5397/5397 [00:00<00:00, 8741.74it/s]\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo1\n",
      "Ultralytics 8.3.174 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=20, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=30, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=models/yolo/fold_1, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=320, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0003, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11l-cls.pt, momentum=0.9, mosaic=1.0, multi_scale=False, name=fold_1, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=models/yolo, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=models/yolo/fold_1, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.01, workers=8, workspace=None\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /kaggle/working/models/yolo/fold_1/train... found 3574 images in 2 classes ✅ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /kaggle/working/models/yolo/fold_1/val... found 3573 images in 2 classes ✅ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  2    173824  ultralytics.nn.modules.block.C3k2            [128, 256, 2, True, 0.25]     \n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  4                  -1  2    691712  ultralytics.nn.modules.block.C3k2            [256, 512, 2, True, 0.25]     \n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  6                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n",
      "  9                  -1  2   1455616  ultralytics.nn.modules.block.C2PSA           [512, 512, 2]                 \n",
      " 10                  -1  1    660482  ultralytics.nn.modules.head.Classify         [512, 2]                      \n",
      "YOLO11l-cls summary: 176 layers, 12,837,186 parameters, 12,837,186 gradients, 49.8 GFLOPs\n",
      "Transferred 492/494 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo1\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 213.3±76.8 MB/s, size: 5.5 KB)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/models/yolo/fold_1/train... 3574 images, 0 corru\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/models/yolo/fold_1/train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 185.8±81.1 MB/s, size: 5.8 KB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/models/yolo/fold_1/val... 3573 images, 0 corrupt: \u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/models/yolo/fold_1/val.cache\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0003, momentum=0.9) with parameter groups 82 weight(decay=0.0), 83 weight(decay=0.009375000000000001), 83 bias(decay=0.0)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mmodels/yolo/fold_1\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "        1/1      2.23G     0.4954         20        320:   2%|▏         | 4/179 \n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralyti\u001b[A\n",
      "        1/1      2.25G     0.3574         14        320: 100%|██████████| 179/17\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 90/90 [00:08<00:0\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "                   all      0.893          1\n",
      "\n",
      "1 epochs completed in 0.011 hours.\n",
      "Optimizer stripped from models/yolo/fold_1/weights/last.pt, 25.9MB\n",
      "Optimizer stripped from models/yolo/fold_1/weights/best.pt, 25.9MB\n",
      "\n",
      "Validating models/yolo/fold_1/weights/best.pt...\n",
      "Ultralytics 8.3.174 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
      "YOLO11l-cls summary (fused): 94 layers, 12,820,994 parameters, 0 gradients, 49.3 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /kaggle/working/models/yolo/fold_1/train... found 3574 images in 2 classes ✅ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /kaggle/working/models/yolo/fold_1/val... found 3573 images in 2 classes ✅ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 90/90 [00:07<00:0\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "                   all      0.893          1\n",
      "Speed: 0.1ms preprocess, 1.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mmodels/yolo/fold_1\u001b[0m\n",
      "✅ Fold 1 model saved at models/yolo/fold_1/best.pt\n",
      "\n",
      "🚀 Training Fold 2/2\n",
      "Preparing train: 100%|████████████████████| 3573/3573 [00:00<00:00, 4221.17it/s]\n",
      "Preparing val: 100%|██████████████████████| 3574/3574 [00:00<00:00, 4482.37it/s]\n",
      "Preparing test: 100%|█████████████████████| 5397/5397 [00:00<00:00, 8457.67it/s]\n",
      "Ultralytics 8.3.174 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=20, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=30, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=models/yolo/fold_2, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=320, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0003, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11l-cls.pt, momentum=0.9, mosaic=1.0, multi_scale=False, name=fold_2, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=models/yolo, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=models/yolo/fold_2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.01, workers=8, workspace=None\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /kaggle/working/models/yolo/fold_2/train... found 3573 images in 2 classes ✅ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /kaggle/working/models/yolo/fold_2/val... found 3574 images in 2 classes ✅ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  2    173824  ultralytics.nn.modules.block.C3k2            [128, 256, 2, True, 0.25]     \n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  4                  -1  2    691712  ultralytics.nn.modules.block.C3k2            [256, 512, 2, True, 0.25]     \n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  6                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n",
      "  9                  -1  2   1455616  ultralytics.nn.modules.block.C2PSA           [512, 512, 2]                 \n",
      " 10                  -1  1    660482  ultralytics.nn.modules.head.Classify         [512, 2]                      \n",
      "YOLO11l-cls summary: 176 layers, 12,837,186 parameters, 12,837,186 gradients, 49.8 GFLOPs\n",
      "Transferred 492/494 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 135.9±62.6 MB/s, size: 5.8 KB)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/models/yolo/fold_2/train... 3573 images, 0 corru\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/models/yolo/fold_2/train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 136.0±54.9 MB/s, size: 5.5 KB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/models/yolo/fold_2/val... 3574 images, 0 corrupt: \u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/models/yolo/fold_2/val.cache\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0003, momentum=0.9) with parameter groups 82 weight(decay=0.0), 83 weight(decay=0.009375000000000001), 83 bias(decay=0.0)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mmodels/yolo/fold_2\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "        1/1      2.45G     0.3334         13        320: 100%|██████████| 179/17\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 90/90 [00:07<00:0\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "                   all      0.895          1\n",
      "\n",
      "1 epochs completed in 0.010 hours.\n",
      "Optimizer stripped from models/yolo/fold_2/weights/last.pt, 25.9MB\n",
      "Optimizer stripped from models/yolo/fold_2/weights/best.pt, 25.9MB\n",
      "\n",
      "Validating models/yolo/fold_2/weights/best.pt...\n",
      "Ultralytics 8.3.174 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
      "YOLO11l-cls summary (fused): 94 layers, 12,820,994 parameters, 0 gradients, 49.3 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /kaggle/working/models/yolo/fold_2/train... found 3573 images in 2 classes ✅ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /kaggle/working/models/yolo/fold_2/val... found 3574 images in 2 classes ✅ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 90/90 [00:07<00:0\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "                   all      0.896          1\n",
      "Speed: 0.2ms preprocess, 1.9ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mmodels/yolo/fold_2\u001b[0m\n",
      "✅ Fold 2 model saved at models/yolo/fold_2/best.pt\n"
     ]
    }
   ],
   "source": [
    "!python main_yolo.py --mode train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T14:44:05.303361Z",
     "iopub.status.busy": "2025-08-06T14:44:05.303127Z",
     "iopub.status.idle": "2025-08-06T14:46:20.117589Z",
     "shell.execute_reply": "2025-08-06T14:46:20.116892Z",
     "shell.execute_reply.started": "2025-08-06T14:44:05.303344Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 inference: 100%|█████████████████████| 5397/5397 [01:04<00:00, 83.35it/s]\n",
      "Fold 2 inference: 100%|█████████████████████| 5397/5397 [01:04<00:00, 84.02it/s]\n",
      "✅ Saved predictions to yolo_submission.csv\n"
     ]
    }
   ],
   "source": [
    "!python main_yolo.py --mode infer"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7191644,
     "sourceId": 11474913,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
